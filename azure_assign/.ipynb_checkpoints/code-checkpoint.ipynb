{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"housing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sing matplotlib and seaborn for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "isualizing missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull(),cmap='Greens',cbar=True,yticklabels=False)\n",
    "plt.title('Missing Data in Total Bedrooms')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hecking as to which feature has missing values using boolean commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o, total_bedrooms has missing values<br>\n",
    "ounting how many rows do not have bedrooms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<b>We have 207 missing values for 'total_bedrooms' which will be handled during the next phase<br>\n",
    "### Data Cleaning, Visualization, Feature Engineering and Selection<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nother version of df.head() but without feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffling all rows(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ategorical Data, so, will enumerate and replace all data with unique values for each type of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ocean_proximity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(data=df,x='ocean_proximity')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace ocean proximity with values to help our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean_proximity = {a:b for b,a in enumerate(df['ocean_proximity'].unique())}\n",
    "df.replace(ocean_proximity, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ocean_proximity.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature 'total_bedrooms' has NaN values so I will replace them with the mean of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "un this cell to check if mean values are populated into the csv. <br>\n",
    "ote that data frame has been shuffled<br>\n",
    "ew=df.to_csv(\"total_bedrooms\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "erifying Data is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df.hist(bins=50,figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nalyzing the median income range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"median_income\"].hist(bins=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix=df.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.displot(df['median_house_value'],color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As we see from above data, house values > 500000 are outliers, so we remove them\n",
    "<br>\n",
    "df[df['median_house_value']>450000]['median_house_value'].value_counts().head()<br>\n",
    "df=df.loc[df['median_house_value']<500001,:]<br>\n",
    "df=df[df['population']<25000]<br>\n",
    "plt.figure(figsize=(14,8))<br>\n",
    "sns.displot(df['median_house_value'],color='magenta')<br>\n",
    "plt.show()<br>\n",
    "b>The outliers of median house value >500000 are removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,7))\n",
    "sns.heatmap(cbar=False,annot=True,data=df.corr()*100,cmap='coolwarm')\n",
    "plt.title('% Corelation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.stripplot(data=df,x='ocean_proximity',y='median_house_value',jitter=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(data=df,x='ocean_proximity',y='median_house_value',palette='viridis')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Modelling and Evaluation\n",
    "<br>\n",
    "X = df.drop('median_house_value',axis=1)<br>\n",
    "y = df['median_house_value']<br>\n",
    "X.head(10)<br>\n",
    "X.shape<br>\n",
    "y.head(10)<br>\n",
    "y.shape<br>\n",
    "from sklearn.model_selection import train_test_split<br>\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.6)<br>\n",
    "print(\"X_train shape is \",X_train.shape)<br>\n",
    "print(\"X_test shape is \",X_test.shape)<br>\n",
    "print(\"y_train shape is \",y_train.shape)<br>\n",
    "print(\"y_test shape is \",y_test.shape)<br>\n",
    "## 1. Random Forest Regressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sing this class to make my print statement look bold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "    BOLD = '\\033[1m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=0)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = rf.score(X_test, y_test)\n",
    "accuracy_rounded = round(accuracy*100,2)\n",
    "accuracies['Random Forest'] = accuracy_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "Adj_r2 = 1-(1-r2)*(9-1)/(9-1-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nR2 score is ',r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nAdjusted R2 score is ',Adj_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nMean Absolute Error is',round(metrics.mean_absolute_error(y_test,rf.predict(X_test)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nMean Squared Error is',round(metrics.mean_squared_error(y_test,rf.predict(X_test)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nRoot Mean Squared Error is',round(np.sqrt(mean_squared_error(y_test,rf.predict(X_test))),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + \"\\nAccuracy of Random Forest Regressor is \", accuracy_rounded,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Decision Tree Regressor\n",
    "<br>\n",
    "from sklearn.tree import DecisionTreeRegressor<br>\n",
    "dt = DecisionTreeRegressor(random_state=42)<br>\n",
    "dt.fit(X_train,y_train)<br>\n",
    "y_pred = dt.predict(X_test)<br>\n",
    "accuracy = dt.score(X_test, y_test)<br>\n",
    "accuracy_rounded = round(accuracy*100,2)<br>\n",
    "accuracies['Decision Tree'] = accuracy_rounded<br>\n",
    "r2 = metrics.r2_score(y_test, y_pred)<br>\n",
    "Adj_r2 = 1-(1-r2)*(9-1)/(9-1-1)<br>\n",
    "print(color.BOLD + '\\nR2 score is ',r2)<br>\n",
    "print(color.BOLD + '\\nAdjusted R2 score is ',Adj_r2)<br>\n",
    "print(color.BOLD + '\\nMean Absolute Error is',round(metrics.mean_absolute_error(y_test,dt.predict(X_test)),2))<br>\n",
    "print(color.BOLD + '\\nMean Squared Error is',round(metrics.mean_squared_error(y_test,dt.predict(X_test)),2))<br>\n",
    "print(color.BOLD + '\\nRoot Mean Squared Error is',round(np.sqrt(metrics.mean_squared_error(y_test,dt.predict(X_test))),2))<br>\n",
    "print(color.BOLD + \"\\nAccuracy of Decision Tree Regressor is \", accuracy_rounded,'%')<br>\n",
    "## 3. AdaBoost Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = ada.score(X_test, y_test)\n",
    "accuracy_rounded = round(accuracy*100,2)\n",
    "accuracies['AdaBoost'] = accuracy_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "Adj_r2 = 1-(1-r2)*(9-1)/(9-1-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nR2 score is ',r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nAdjusted R2 score is ',Adj_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nMean Absolute Error is',round(metrics.mean_absolute_error(y_test,ada.predict(X_test)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nMean Squared Error is',round(metrics.mean_squared_error(y_test,ada.predict(X_test)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nRoot Mean Squared Error is',round(np.sqrt(mean_squared_error(y_test,ada.predict(X_test))),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + \"\\nAccuracy of AdaBoost Regressor is \", accuracy_rounded,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. XGBoost Regressor\n",
    "<br>\n",
    "from xgboost import XGBRegressor<br>\n",
    "from sklearn.metrics import accuracy_score<br>\n",
    "xg = XGBRegressor()<br>\n",
    "xg.fit(X_train,y_train)<br>\n",
    "y_pred = xg.predict(X_test)<br>\n",
    "accuracy = xg.score(X_test, y_test)<br>\n",
    "accuracy_rounded = round(accuracy*100,2)<br>\n",
    "accuracies['XGBoost'] = accuracy_rounded<br>\n",
    "r2 = metrics.r2_score(y_test, y_pred)<br>\n",
    "Adj_r2 = 1-(1-r2)*(9-1)/(9-1-1)<br>\n",
    "print(color.BOLD + '\\nR2 score is ',r2)<br>\n",
    "print(color.BOLD + '\\nAdjusted R2 score is ',Adj_r2)<br>\n",
    "print(color.BOLD + '\\nMean Absolute Error is',round(metrics.mean_absolute_error(y_test,xg.predict(X_test)),2))<br>\n",
    "print(color.BOLD + '\\nMean Squared Error is',round(metrics.mean_squared_error(y_test,xg.predict(X_test)),2))<br>\n",
    "print(color.BOLD + '\\nRoot Mean Squared Error is',round(np.sqrt(mean_squared_error(y_test,xg.predict(X_test))),2))<br>\n",
    "print(color.BOLD + \"\\nAccuracy of XGBoost Regressor is \", accuracy_rounded,'%')<br>\n",
    "## 5. Gradient Boost Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = GradientBoostingRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = gboost.score(X_test, y_test)\n",
    "accuracy_rounded = round(accuracy*100,2)\n",
    "accuracies['Gradient Boost'] = accuracy_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "Adj_r2 = 1-(1-r2)*(9-1)/(9-1-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nR2 score is ',r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nAdjusted R2 score is ',Adj_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nMean Absolute Error is',round(metrics.mean_absolute_error(y_test,gboost.predict(X_test)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nMean Squared Error is',round(metrics.mean_squared_error(y_test,gboost.predict(X_test)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nRoot Mean Squared Error is',round(np.sqrt(mean_squared_error(y_test,gboost.predict(X_test))),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + \"\\nAccuracy of Gradient Boost Regressor is \", accuracy_rounded,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 6. Ridge Regression\n",
    "<br>\n",
    "from sklearn.linear_model import Ridge<br>\n",
    "rid = Ridge(alpha=0.1)<br>\n",
    "rid.fit(X_train,y_train)<br>\n",
    "y_pred = rid.predict(X_test)<br>\n",
    "accuracy = rid.score(X_test, y_test)<br>\n",
    "accuracy_rounded = round(accuracy*100,2)<br>\n",
    "accuracies['Ridge Regression'] = accuracy_rounded<br>\n",
    "r2 = metrics.r2_score(y_test, y_pred)<br>\n",
    "Adj_r2 = 1-(1-r2)*(9-1)/(9-1-1)<br>\n",
    "print(color.BOLD + '\\nR2 score is ',r2)<br>\n",
    "print(color.BOLD + '\\nAdjusted R2 score is ',Adj_r2)<br>\n",
    "print(color.BOLD + '\\nMean Absolute Error is',round(metrics.mean_absolute_error(y_test,rid.predict(X_test)),2))<br>\n",
    "print(color.BOLD + '\\nMean Squared Error is',round(metrics.mean_squared_error(y_test,rid.predict(X_test)),2))<br>\n",
    "print(color.BOLD + '\\nRoot Mean Squared Error is',round(np.sqrt(mean_squared_error(y_test,rid.predict(X_test))),2))<br>\n",
    "print(color.BOLD + \"\\nAccuracy of Ridge Regression is \", accuracy_rounded,'%')<br>\n",
    "## 7. Lasso Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = linear_model.Lasso(alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = lasso.score(X_test, y_test)\n",
    "accuracy_rounded = round(accuracy*100,2)\n",
    "accuracies['Lasso Regression'] = accuracy_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "Adj_r2 = 1-(1-r2)*(9-1)/(9-1-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nR2 score is ',r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nAdjusted R2 score is ',Adj_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nMean Absolute Error is',round(metrics.mean_absolute_error(y_test,lasso.predict(X_test)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nMean Squared Error is',round(metrics.mean_squared_error(y_test,lasso.predict(X_test)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nRoot Mean Squared Error is',round(np.sqrt(mean_squared_error(y_test,lasso.predict(X_test))),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + \"\\nAccuracy of Lasso Regression is \", accuracy_rounded,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 8. ElasticNet Regression\n",
    "<br>\n",
    "from sklearn.linear_model import ElasticNet<br>\n",
    "ela = ElasticNet(random_state=0)<br>\n",
    "ela.fit(X_train,y_train)<br>\n",
    "y_pred = ela.predict(X_test)<br>\n",
    "accuracy = ela.score(X_test, y_test)<br>\n",
    "accuracy_rounded = round(accuracy*100,2)<br>\n",
    "accuracies['Elastic Net Regression'] = accuracy_rounded<br>\n",
    "r2 = metrics.r2_score(y_test, y_pred)<br>\n",
    "Adj_r2 = 1-(1-r2)*(9-1)/(9-1-1)<br>\n",
    "print(color.BOLD + '\\nR2 score is ',r2)<br>\n",
    "print(color.BOLD + '\\nAdjusted R2 score is ',Adj_r2)<br>\n",
    "print(color.BOLD + '\\nMean Absolute Error is',round(metrics.mean_absolute_error(y_test,ela.predict(X_test)),2))<br>\n",
    "print(color.BOLD + '\\nMean Squared Error is',round(metrics.mean_squared_error(y_test,ela.predict(X_test)),2))<br>\n",
    "print(color.BOLD + '\\nRoot Mean Squared Error is',round(np.sqrt(mean_squared_error(y_test,ela.predict(X_test))),2))<br>\n",
    "print(color.BOLD + \"\\nAccuracy of Elastic net Regression is \", accuracy_rounded,'%')<br>\n",
    "from catboost import CatBoostRegressor<br>\n",
    "cat = CatBoostRegressor()<br>\n",
    "cat.fit(X_train,y_train)<br>\n",
    "y_pred = cat.predict(X_test)<br>\n",
    "accuracy = cat.score(X_test, y_test)<br>\n",
    "accuracy_rounded = round(accuracy*100,2)<br>\n",
    "accuracies['CatBoost'] = accuracy_rounded<br>\n",
    "r2 = metrics.r2_score(y_test, y_pred)<br>\n",
    "Adj_r2 = 1-(1-r2)*(9-1)/(9-1-1)<br>\n",
    "print(color.BOLD + '\\nR2 score is ',r2)<br>\n",
    "print(color.BOLD + '\\nAdjusted R2 score is ',Adj_r2)<br>\n",
    "print(color.BOLD + '\\nMean Absolute Error is',round(metrics.mean_absolute_error(y_test,cat.predict(X_test)),2))<br>\n",
    "print(color.BOLD + '\\nMean Squared Error is',round(metrics.mean_squared_error(y_test,cat.predict(X_test)),2))<br>\n",
    "print(color.BOLD + '\\nRoot Mean Squared Error is',round(np.sqrt(mean_squared_error(y_test,cat.predict(X_test))),2))<br>\n",
    "print(color.BOLD + \"\\nAccuracy of CatBoost is \", accuracy_rounded,'%')<br>\n",
    "import lightgbm as lgb<br>\n",
    "lg = lgb.LGBMRegressor()<br>\n",
    "lg.fit(X_train,y_train)<br>\n",
    "y_pred = lg.predict(X_test)<br>\n",
    "accuracy = lg.score(X_test, y_test)<br>\n",
    "accuracy_rounded = round(accuracy*100,2)<br>\n",
    "accuracies['Light GBM'] = accuracy_rounded<br>\n",
    "r2 = metrics.r2_score(y_test, y_pred)<br>\n",
    "Adj_r2 = 1-(1-r2)*(9-1)/(9-1-1)<br>\n",
    "print(color.BOLD + '\\nR2 score is ',r2)<br>\n",
    "print(color.BOLD + '\\nAdjusted R2 score is ',Adj_r2)<br>\n",
    "print(color.BOLD + '\\nMean Absolute Error is',round(metrics.mean_absolute_error(y_test,lg.predict(X_test)),2))<br>\n",
    "print(color.BOLD + '\\nMean Squared Error is',round(metrics.mean_squared_error(y_test,lg.predict(X_test)),2))<br>\n",
    "print(color.BOLD + '\\nRoot Mean Squared Error is',round(np.sqrt(mean_squared_error(y_test,lg.predict(X_test))),2))<br>\n",
    "print(color.BOLD + \"\\nAccuracy of Light GBM is \", accuracy_rounded,'%')<br>\n",
    "#Verifying how untuned models predict house value<br>\n",
    "print('\\nPrediction of Random Forest is ',rf.predict([[-122.22,37.86,21,7099,1106,2401,1138,8.3014,0]]))      <br>\n",
    "print('\\nPrediction of Ada Boost is ',ada.predict([[-122.22,37.86,21,7099,1106,2401,1138,8.3014,0]])) <br>\n",
    "print('\\nPrediction of Gradient Boost is ',gboost.predict([[-122.22,37.86,21,7099,1106,2401,1138,8.3014,0]]))<br>\n",
    "print('\\nPrediction of Ridge Regression is ',rid.predict([[-122.22,37.86,21,7099,1106,2401,1138,8.3014,0]]))<br>\n",
    "print('\\nPrediction of Lasso Regression is ',lasso.predict([[-122.22,37.86,21,7099,1106,2401,1138,8.3014,0]]))<br>\n",
    "print('\\nPrediction of Elasticnet Regression is ',ela.predict([[-122.22,37.86,21,7099,1106,2401,1138,8.3014,0]]))<br>\n",
    "print('\\nPrediction of Decision Tree is ',dt.predict([[-122.22,37.86,21,7099,1106,2401,1138,8.3014,0]]))<br>\n",
    "print('\\nPrediction of CatBoost is ',cat.predict([[-122.22,37.86,21,7099,1106,2401,1138,8.3014,0]]))<br>\n",
    "print('\\nPrediction of Light GBM is ',lg.predict([[-122.22,37.86,21,7099,1106,2401,1138,8.3014,0]]))<br>\n",
    "## All accuracies together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lotting accuracies of all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"green\", \"yellow\", \"black\", \"magenta\", \"#0e76a8\", \"red\", \"#34558b\",\"#f0daa4\",\"#3b3d4b\",\"#fd823e\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.yticks(np.arange(0,100,10))\n",
    "plt.ylabel(\"\\nAccuracy %\",fontsize=20)\n",
    "plt.xlabel(\"\\nAlgorithms\",fontsize=20)\n",
    "sns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()), palette=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "atBoost performs the best without tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Hyperparameter Tuning<br>\n",
    "> Let's try to increase the accuracy of the top performing models on this dataset - <br>\n",
    "> 1.   RandomForest<br>\n",
    "2.   CatBoost<br>\n",
    "1.   LightGBM<br>\n",
    "---<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Random Forest Tuning\n",
    "<br>\n",
    "#Randomized Search CV<br>\n",
    "# Number of trees in the random forest<br>\n",
    "n_estimators = [int(x) for x in np.linspace(start = 5, stop = 300, num = 6)]<br>\n",
    "# Number of features to consider at every split<br>\n",
    "max_features = ['auto', 'sqrt', 'log2']<br>\n",
    "# Maximum number of levels in tree<br>\n",
    "max_depth = [int(x) for x in np.linspace(10, 120, num = 12)]<br>\n",
    "max_depth.append(None)<br>\n",
    "# Minimum number of samples required to split a node<br>\n",
    "min_samples_split = [2, 5, 10, 13, 16]<br>\n",
    "# Minimum number of samples required at each leaf node<br>\n",
    "min_samples_leaf = [1, 2, 4, 8]<br>\n",
    "# Method of selecting samples for training each tree<br>\n",
    "bootstrap = [True, False]<br>\n",
    "# Create the random grid<br>\n",
    "random_grid = {'n_estimators': n_estimators,<br>\n",
    "               'max_features': max_features,<br>\n",
    "               'max_depth': max_depth,<br>\n",
    "               'min_samples_split': min_samples_split,<br>\n",
    "               'min_samples_leaf': min_samples_leaf,<br>\n",
    "               'bootstrap': bootstrap}<br>\n",
    "print(random_grid)<br>\n",
    "rf_random = RandomizedSearchCV(estimator = rf, <br>\n",
    "                               param_distributions = random_grid, <br>\n",
    "                               n_iter = 9, <br>\n",
    "                               cv = 4, <br>\n",
    "                               verbose=0,<br>\n",
    "                               random_state=42, <br>\n",
    "                               n_jobs = -1)<br>\n",
    "rf_random.fit(X_train, y_train)<br>\n",
    "rf_random.best_params_<br>\n",
    "#Predict on test data<br>\n",
    "y_pred = rf_random.predict(X_test)<br>\n",
    "#Metrics Calculation<br>\n",
    "r2 = round(metrics.r2_score(y_test, y_pred),2)<br>\n",
    "Adj_r2 = round(1-(1-r2)*(9-1)/(9-1-1),2)<br>\n",
    "#Display results<br>\n",
    "print(color.BOLD + '\\nR2 score is ',r2)<br>\n",
    "print(color.BOLD + '\\nAdjusted R2 score is ',Adj_r2)<br>\n",
    "print(color.BOLD + '\\nMean Absolute Error is',round(metrics.mean_absolute_error(y_test,rf_random.predict(X_test)),2))<br>\n",
    "print(color.BOLD + '\\nMean Squared Error is',round(metrics.mean_squared_error(y_test,rf_random.predict(X_test)),2))<br>\n",
    "print(color.BOLD + '\\nRoot Mean Squared Error is',round(np.sqrt(mean_squared_error(y_test,rf_random.predict(X_test))),2))<br>\n",
    "#Grid Search CV<br>\n",
    "param_grid = {<br>\n",
    "    'bootstrap': [True],<br>\n",
    "    'max_depth': [80, 90, 100],<br>\n",
    "    'max_features': [2, 3],<br>\n",
    "    'min_samples_leaf': [3, 4, 5],<br>\n",
    "    'min_samples_split': [4, 8, 10],<br>\n",
    "    'n_estimators': [100, 200, 300]<br>\n",
    "}<br>\n",
    "# Instantiate the grid search model<br>\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 2, n_jobs = -1, verbose = 0)<br>\n",
    "grid_search.fit(X_train,y_train)<br>\n",
    "grid_search.best_params_<br>\n",
    "best_grid = grid_search.best_estimator_<br>\n",
    "best_grid<br>\n",
    "#Predict on test data<br>\n",
    "y_pred = best_grid.predict(X_test)<br>\n",
    "#Metrics Calculation<br>\n",
    "r2 = round(metrics.r2_score(y_test, y_pred),2)<br>\n",
    "Adj_r2 = round(1-(1-r2)*(9-1)/(9-1-1),2)<br>\n",
    "#Display results<br>\n",
    "print(color.BOLD + '\\nR2 score is ',r2)<br>\n",
    "print(color.BOLD + '\\nAdjusted R2 score is ',Adj_r2)<br>\n",
    "print(color.BOLD + '\\nMean Absolute Error is',round(metrics.mean_absolute_error(y_test,rf_random.predict(X_test)),2))<br>\n",
    "print(color.BOLD + '\\nMean Squared Error is',round(metrics.mean_squared_error(y_test,rf_random.predict(X_test)),2))<br>\n",
    "print(color.BOLD + '\\nRoot Mean Squared Error is',round(np.sqrt(mean_squared_error(y_test,rf_random.predict(X_test))),2))<br>\n",
    "## CatBoost Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "andomized Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 5 , stop = 150, num = 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [int(x) for x in np.linspace(2, 120, num = 2)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'n_estimators': n_estimators, 'learning_rate' : np.linspace(0,0.3,5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(      estimator=cat, \n",
    "                                param_distributions=grid, \n",
    "                                n_iter = 10, \n",
    "                                scoring='r2',\n",
    "                                cv = 5, \n",
    "                                verbose=0, \n",
    "                                random_state=42,\n",
    "                                n_jobs=-1,\n",
    "                                return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summarize result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rscv.best_params_)\n",
    "print(rscv.score(X_test , y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "redict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rscv.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "etrics Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = round(metrics.r2_score(y_test, y_pred),2)\n",
    "Adj_r2 = round(1-(1-r2)*(9-1)/(9-1-1),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "isplay results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nR2 score is ',r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nAdjusted R2 score is ',Adj_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nMean Absolute Error is',round(metrics.mean_absolute_error(y_test,rscv.predict(X_test)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nMean Squared Error is',round(metrics.mean_squared_error(y_test,rscv.predict(X_test)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + '\\nRoot Mean Squared Error is',round(np.sqrt(mean_squared_error(y_test,rscv.predict(X_test))),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Light GBM Tuning\n",
    "<br>\n",
    "#Randomized Search CV<br>\n",
    "n_estimators = [int(x) for x in np.linspace(start = 5 , stop = 350, num = 2)]<br>\n",
    "max_depth = [int(x) for x in np.linspace(3, 450, num = 3)] <br>\n",
    "max_depth.append(None)<br>\n",
    "grid = {'n_estimators': n_estimators,'learning_rate' : np.linspace(0,0.5,5)}<br>\n",
    "print(grid)<br>\n",
    "rscv = RandomizedSearchCV(      estimator=lg, <br>\n",
    "                                param_distributions=grid, <br>\n",
    "                                n_iter = 15, <br>\n",
    "                                scoring='r2',<br>\n",
    "                                cv = 10, <br>\n",
    "                                verbose=0, <br>\n",
    "                                random_state=42,<br>\n",
    "                                n_jobs=-1,<br>\n",
    "                                return_train_score=True)<br>\n",
    "rscv.fit(X_train, y_train)<br>\n",
    "# summarize result<br>\n",
    "print(rscv.best_params_)<br>\n",
    "print(rscv.score(X_test , y_test))<br>\n",
    "#Predict on test data<br>\n",
    "y_pred = rscv.predict(X_test)<br>\n",
    "#Metrics Calculation<br>\n",
    "r2 = round(metrics.r2_score(y_test, y_pred),2)<br>\n",
    "Adj_r2 = round(1-(1-r2)*(9-1)/(9-1-1),2)<br>\n",
    "#Display results<br>\n",
    "print(color.BOLD + '\\nR2 score is ',r2)<br>\n",
    "print(color.BOLD + '\\nAdjusted R2 score is ',Adj_r2)<br>\n",
    "print(color.BOLD + '\\nMean Absolute Error is',round(metrics.mean_absolute_error(y_test,rscv.predict(X_test)),2))<br>\n",
    "print(color.BOLD + '\\nMean Squared Error is',round(metrics.mean_squared_error(y_test,rscv.predict(X_test)),2))<br>\n",
    "print(color.BOLD + '\\nRoot Mean Squared Error is',round(np.sqrt(mean_squared_error(y_test,rscv.predict(X_test))),2))<br>\n",
    "## Exporting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "> Based on hyperparameter tuning, we can either choose Catboost or LightGBM(top-performer)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xporting the model using joblib library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(lg,\"California_Model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
